<!DOCTYPE html>
<html lang="en">
  <html>
    <head>
      <meta charset="UTF-8" />
      <meta http-equiv="X-UA-Compatible" content="IE=edge" />
      <meta name="viewport" content="width=device-width, initial-scale0" />
      <title>Voice recorder</title>
      <style>
        * {
          margin: 0p;
          padding: 0;
          box-sizing: border-box;
        }
        body {
          font-family: Arial, Helvetica, sans-serif;
          text-align: center;
          margin-top: 20%;
        }
        button {
          padding: 7px 20px;
          cursor: pointer;
        }

        #response {
          background-color: #e0e0e0;
          border-radius: 8px;
          margin-top: 20px;
          padding: 12px;
          width: fit-content;
          margin-left: auto;
          margin-right: auto;
        }
      </style>
      <script src="https://cdn.jsdelivr.net/npm/axios@1.6.2/dist/axios.min.js"></script>
      <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>
    </head>
    <body>
      <button id="startRecording">Start</button>
      <button id="stopRecording">Stop</button>
      <br />
      <p id="isRecording">Click start button to record</p>
      <audio src="" id="audioElement" controls></audio>
      <div id="response">No Transcription Available</div>

      <script>
        let transcribedData = "";
        let formData;
        let recordAudio;
        let hasInitialResponse = false;

        document
          .getElementById("startRecording")
          .addEventListener("click", initFunction);
        let isRecording = document.getElementById("isRecording");

        function initFunction() {
          function getResponse(text) {
            axios
              .post("http://localhost:3000/respond", { text })
              .then(function (response) {
                console.log(response);
              })
              .catch(function (err) {
                console.log(err);
              });
          }

          function getFormattedTranscribedData(data, time) {
            return `<i>${data}</i>   <b>${time / 1000} sec</b> <br/>`;
          }

          function createBlob(blob, isLast = false) {
            formData = new FormData();
            formData.append("file", blob);
            document.getElementById("audioElement").src =
              URL.createObjectURL(blob);
            transcribeAudio(formData, isLast);
          }

          async function transcribeAudio(formData, isLast = false) {
            let sendDate = new Date().getTime();

            if (isLast) {
              formData.append("lastChunk", true);
            }

            axios
              .post("http://localhost:3000/upload", formData, {
                "Content-type": "multipart/form-data",
              })
              .then(async function (response) {
                let receiveDate = new Date().getTime();
                let responseTime = receiveDate - sendDate;
                transcribedData += " " + response.data;

                if (!hasInitialResponse) {
                  document.getElementById("response").innerHTML = "";
                  hasInitialResponse = true;
                }

                document.getElementById("response").innerHTML +=
                  getFormattedTranscribedData(chatMessage.value, null);

                return response;
              })
              .catch(function (err) {
                console.log(err);
              });
          }

          async function getUserMedia(constraints) {
            if (window.navigator.mediaDevices) {
              return window.navigator.mediaDevices.getUserMedia(constraints);
            }
            let legacyApi =
              navigator.getUserMedia ||
              navigator.webkitGetUserMedia ||
              navigator.mozGetUserMedia ||
              navigator.msGetUserMedia;
            if (legacyApi) {
              return new Promise(function (resolve, reject) {
                legacyApi.bind(window.navigator)(constraints, resolve, reject);
              });
            } else {
              alert("user api not supported");
            }
          }

          isRecording.textContent = "Recording...";

          function handlerFunction(stream) {
            recordAudio = RecordRTC(stream, {
              type: "audio",
              mimeType: "audio/wav",
              sampleRate: 44100,
              desiredSampRate: 16000,
              timeSlice: 3000,
              recorderType: StereoAudioRecorder,
              numberOfAudioChannels: 1,
              checkForInactiveTracks: true,
              ondataavailable: function (blob) {
                //createBlob(blob);
              },
            });
            recordAudio.startRecording();
          }

          function startusingBrowserMicrophone(boolean) {
            getUserMedia({ audio: boolean }).then((stream) => {
              handlerFunction(stream);
            });
          }

          startusingBrowserMicrophone(true);

          document
            .getElementById("stopRecording")
            .addEventListener("click", (e) => {
              recordAudio.stopRecording(function (blob) {
                // 2. In case you want to sent all audio at once
                //createBlob(recordAudio.blob, true);

                createBlob(recordAudio.getBlob(), true);
                document.getElementById("audioElement").src = blob;
              });
              isRecording.textContent = "Click play button to start listening";
            });
        }
      </script>
    </body>
  </html>
</html>
