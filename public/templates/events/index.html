<!DOCTYPE html>
<html lang="en">
  <html>
    <head>
      <meta charset="UTF-8" />
      <meta http-equiv="X-UA-Compatible" content="IE=edge" />
      <meta name="viewport" content="width=device-width, initial-scale=0" />
      <title>Voice recorder</title>
      <link
        href="https://fonts.googleapis.com/css2?family=Roboto:wght@100;300;400;500&display=swap"
        rel="stylesheet"
      />
      <link
        rel="stylesheet"
        href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200"
      />
      <link
        rel="stylesheet"
        href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/4.1.1/animate.min.css"
      />
      <style>
        * {
          margin: 0px;
          padding: 0;
          box-sizing: border-box;
        }

        button {
          padding: 7px 20px;
          cursor: pointer;
        }

        #response {
          background-color: #e0e0e0;
          border-radius: 8px;
          margin-top: 24px;
          padding: 12px;
          width: fit-content;
          margin-left: auto;
          margin-right: auto;
          font-family: Roboto;
          font-weight: 300;
          text-align: center;
        }

        .header {
          display: flex;
          background-color: #265073;
          height: 60px;
          padding: 10px;
          color: #fff;
          font-family: Roboto;
          font-size: 20px;
          line-height: 60px;
          justify-content: space-between;
        }

        .header-container {
          display: flex;
        }

        .heading {
          font-family: Roboto;
          margin-left: 5px;
          line-height: 40px;
          font-weight: 400;
        }

        .beta {
          font-size: 12px;
          background-color: #3f6f98;
          margin-left: 8px;
          width: fit-content;
          height: 20px;
          line-height: 20px;
          padding-left: 3px;
          padding-right: 3px;
          margin-top: 10px;
        }

        .bot-version {
          font-size: 20px;
          margin-right: 8px;
          font-weight: 300;
        }

        .container {
          padding: 35px;
        }

        .mic-container {
          width: 120px;
          height: 120px;
          border-radius: 50%;
          text-align: center;
          line-height: 1200px;
          background-color: #e0e0e0;
          color: gray;
          margin-left: auto;
          margin-right: auto;
          margin-top: 150px;
          cursor: pointer;
        }

        .mic-container > span {
          font-size: 60px;
          display: block;
          line-height: 120px;
        }

        .mic-on {
          color: white;
        }

        .mic-container-on-color {
          background-color: #2d9596;
        }

        #stopRecording {
          display: none;
        }
      </style>

      <script src="https://cdn.jsdelivr.net/npm/axios@1.6.2/dist/axios.min.js"></script>
      <script src="https://www.WebRTC-Experiment.com/RecordRTC.js"></script>
      <script
        src="https://cdn.socket.io/4.7.2/socket.io.min.js"
        integrity="sha384-mZLF4UVrpi/QTWPA7BjNPEnkIfRFn4ZEO3Qt/HFklTJBj/gBOV8G3HcKn4NfQblz"
        crossorigin="anonymous"
      ></script>
    </head>
    <body>
      <section class="header">
        <div class="header-container">
          <img src="../../assets/conrad-labs-logo.png" />
          <div class="heading">Voice Assistant</div>
          <div class="beta">BETA</div>
        </div>
        <div class="bot-version">v1.3</div>
      </section>

      <section class="container">
        <div id="startRecording" class="mic-container">
          <span class="material-symbols-outlined"> mic_off </span>
        </div>

        <div id="stopRecording" class="mic-container mic-container-on-color">
          <span class="material-symbols-outlined mic-on"> mic </span>
        </div>

        <div id="response">No Transcription Available</div>
        <audio
          id="pop"
          src="https://assets.mixkit.co/active_storage/sfx/2364/2364-preview.mp3"
        ></audio>
      </section>

      <script src="https://cdnjs.cloudflare.com/ajax/libs/pubsub-js/1.9.4/pubsub.min.js"></script>
      <script>
        let formData;
        let recordAudio;
        let startTime,
          timeTaken,
          endTime = null;
        let responseData = "";
        let source;
        let context = new AudioContext();
        let time = 0;

        document
          .getElementById("startRecording")
          .addEventListener("click", initFunction, false);
        let isRecording = document.getElementById("isRecording");

        document.getElementById("stopRecording").addEventListener(
          "click",
          (e) => {
            recordAudio.stopRecording(function (blob) {
              document.getElementById("startRecording").style.display = "block";
              document.getElementById("stopRecording").style.display = "none";

              startTime = new Date().getTime();
              document.getElementById("response").innerHTML = "Processing ...";
              createBlob(recordAudio.blob, true);
            });
          },
          false
        );

        function initFunction() {
          document.getElementById("pop").play();
          document.getElementById("startRecording").style.display = "none";
          document.getElementById("stopRecording").style.display = "block";
          time = 0;

          async function getUserMedia(constraints) {
            if (window.navigator.mediaDevices) {
              return window.navigator.mediaDevices.getUserMedia(constraints);
            }
            let legacyApi =
              navigator.getUserMedia ||
              navigator.webkitGetUserMedia ||
              navigator.mozGetUserMedia ||
              navigator.msGetUserMedia;
            if (legacyApi) {
              return new Promise(function (resolve, reject) {
                legacyApi.bind(window.navigator)(constraints, resolve, reject);
              });
            } else {
              alert("user api not supported");
            }
          }

          function handlerFunction(stream) {
            recordAudio = RecordRTC(stream, {
              type: "audio",
              mimeType: "audio/wav",
              sampleRate: 44100,
              desiredSampRate: 16000,
              timeSlice: 3500,
              disableLogs: true,
              recorderType: StereoAudioRecorder,
              numberOfAudioChannels: 1,
              ondataavailable: function (blob) {},
            });
            recordAudio.startRecording();
          }

          function startusingBrowserMicrophone(boolean) {
            getUserMedia({ audio: boolean }).then((stream) => {
              handlerFunction(stream);
            });
          }

          startusingBrowserMicrophone(true);
        }

        function getFormattedTranscribedText(data, time) {
          return `<div style="margin-top: 8px;"><i>${data}</i> <b>${time} sec</b></div>`;
        }

        async function createBlob(blob, isLast = false) {
          formData = new FormData();
          formData.append("file", blob);
          await transcribeAudio(formData, isLast);
        }

        let audioSubscriber = async function (message, data) {
            await processChunks(data);
        };
        PubSub.subscribe("Audio", audioSubscriber);

        async function transcribeAudio(formData, isLast = false) {
          if (isLast) {
            formData.append("lastChunk", true);
          }

          const response = await fetch(`http://localhost:3000/upload-v2`, {
            method: "POST",
            body: formData,
          });

          let chatMessage = "";
          let streamChunkStarted = false;
          let streamChunkEnded = false;
          let streamChunkData = "";
          let reader = response.body.getReader();

          let chunks = [];
          let counter = 0;
          const MAX_CHUNK_COUNTER = 2;

          while (reader) {
            let stream = await reader.read();

            if (stream.done) {
              console.log("DONE");
              endTime = new Date().getTime();
              timeTaken = (endTime - startTime) / 1000;
              PubSub.publish("Audio", chunks);
              chunks = [];
              counter = 0;
              break;
            } else {
              console.log(stream.value);
              if (counter < MAX_CHUNK_COUNTER) {
                chunks.push(stream.value);
                counter++;
              } else {
                PubSub.publish("Audio", chunks);
                chunks = [];
                counter = 0;
                chunks.push(stream.value);
              }
            }
          }
        }

        async function processChunks(chunks) {
          const mergedChunks = Uint8Array.from(
            chunks.reduce((acc, curr) => [...acc, ...curr], [])
          );
          speakStreamChunk(mergedChunks.buffer);
        }

        function showTextResponse(response) {
          document.getElementById("response").innerHTML = "";
          endTime = new Date().getTime();
          timeTaken = (endTime - startTime) / 1000;
          console.log(`Response Received In ${timeTaken}`);
          responseData += getFormattedTranscribedText(response, timeTaken);
          document.getElementById("response").innerHTML += responseData;
          console.log(`Response - ${response}`);
        }

        function speakStreamChunk(response) {
          context.decodeAudioData(response, function (soundBuffer) {
            streamAudioBuffer(soundBuffer, context);
          });
        }

        function streamAudioBuffer(buffer, context) {
          source = context.createBufferSource();
          source.buffer = buffer;
          source.connect(context.destination);
          source.loop = false;

          let contextWindow = context.currentTime;
          source.start(time + contextWindow);
          time += buffer.duration;
        }
      </script>
    </body>
  </html>
</html>
